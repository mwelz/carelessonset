% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/carelessonset.R
\name{carelessonset}
\alias{carelessonset}
\title{detect the onset of careless responding
TODO: the order at which alpha is passed seems to matter, otherwise get_changpoint() output has the changepoints of the wrong dimension. This error is in R/changepoints/multivariate.r (and possibly also univariate) EDIT: fixed it, but double-check! Also, autoencoder() prompts training process (verbose); change that. Also, currently a miniconda installation  of python is implicitly required. Make that explicit and add an installer function. Also, some functions are not exported properly (so cannot be called with ordinary namespace)}
\usage{
carelessonset(
  responses,
  num_scales,
  num_likert,
  time = NULL,
  longstring = TRUE,
  item_order = NULL,
  alpha = c(0.005, 0.001),
  mc_cores = parallel::detectCores(),
  encoder_width = floor(1.5 * ncol(responses)),
  encoder_activation = "tanh",
  bottleneck_activation = "linear",
  loss = get_pseudo_huber(),
  optimizer = keras::optimizer_sgd(learning_rate = 1e-04),
  kernel_regularizer_HL1 = NULL,
  bias_regularizer_HL1 = NULL,
  maxlen = max(num_likert),
  epochs = 100L,
  batch_size = 10L,
  verbose = 0L,
  seed = NULL
)
}
\arguments{
\item{responses}{data matrix that holds the responses of a given respondent in its rows. Must be in the order as presented to each participant}

\item{num_scales}{number of psychometric scales in the data}

\item{num_likert}{number of likert-type respnse options (TODO: allow for vector-valued input)}

\item{time}{data matrix of per-item response time (TODO: allow for per-page time passing)}

\item{longstring}{shall longstring indices be computed and used?}

\item{item_order}{A matrix holding the item indices on the participant level. If responses ae reshuffled according to this order, then each column in the response matrix are responses to the same item}

\item{alpha}{significance levels}

\item{mc_cores}{number of cores for parallelization}

\item{encoder_width}{TODO}

\item{encoder_activation}{TODO}

\item{bottleneck_activation}{TODO}

\item{loss}{a function object for the loss function}

\item{optimizer}{keras object for the optimizer}

\item{kernel_regularizer_HL1}{regularization imposed in hidden layer on weights}

\item{bias_regularizer_HL1}{regularization imposed in hidden layer on biases}

\item{maxlen}{Maximum length of an LSP pattern}

\item{epochs}{number of epochs}

\item{batch_size}{batch size}

\item{verbose}{manage prints}

\item{seed}{random seed}
}
\description{
detect the onset of careless responding
TODO: the order at which alpha is passed seems to matter, otherwise get_changpoint() output has the changepoints of the wrong dimension. This error is in R/changepoints/multivariate.r (and possibly also univariate) EDIT: fixed it, but double-check! Also, autoencoder() prompts training process (verbose); change that. Also, currently a miniconda installation  of python is implicitly required. Make that explicit and add an installer function. Also, some functions are not exported properly (so cannot be called with ordinary namespace)
}
